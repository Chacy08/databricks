{"cells":[{"cell_type":"markdown","source":["# Describe the difference between eager and lazy execution"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b94b3918-cc42-47e1-b780-100c428afedf","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"448856a1-1a6b-40d4-9a17-686fa8c0780d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"165142ba-4fed-430f-a51a-5b34896457fd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Laziness By Design\n\nFundamental to Apache Spark are the notions that\n* Transformations are **LAZY**\n* Actions are **EAGER**\n\nThe following code condenses the logic from the DataFrames modules in this learning path, and uses the DataFrames API to:\n- Specify a schema, format, and file source for the data to be loaded\n- Select columns to `GROUP BY`\n- Aggregate with a `COUNT`\n- Provide an alias name for the aggregate output\n- Specify a column to sort on\n\nThis cell defines a series of **transformations**. By definition, this logic will result in a DataFrame and will not trigger any jobs."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b6e9cfb0-c8c4-44ce-9244-f03a5ac33a8d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["schemaDDL = \"NAME STRING, STATION STRING, LATITUDE FLOAT, LONGITUDE FLOAT, ELEVATION FLOAT, DATE DATE, UNIT STRING, TAVG FLOAT\"\n\nsourcePath = \"/mnt/training/weather/StationData/stationData.parquet/\"\n\ncountsDF = (spark.read\n  .format(\"parquet\")\n  .schema(schemaDDL)\n  .load(sourcePath)\n  .groupBy(\"NAME\", \"UNIT\").count()\n  .withColumnRenamed(\"count\", \"counts\")\n  .orderBy(\"NAME\")\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1aa06034-501d-4441-8e35-cd93d5dec529","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Because `display` is an **action**, a job _will_ be triggered, as logic is executed against the specified data to return a result."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7c6c043b-a486-4d1f-979d-9b2f5bc0d64a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["display(countsDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"74b36d2a-dbeb-49f4-940b-9547ab3fe748","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Why is Laziness So Important?\n\nLaziness is at the core of Scala and Spark.\n\nIt has a number of benefits:\n* Not forced to load all data at step #1\n  * Technically impossible with **REALLY** large datasets.\n* Easier to parallelize operations\n  * N different transformations can be processed on a single data element, on a single thread, on a single machine.\n* Optimizations can be applied prior to code compilation"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a7ab20bc-bb61-40b6-acce-5b253eaccccc","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"1.Eager-and-Lazy-execution","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4208893588635990}},"nbformat":4,"nbformat_minor":0}
